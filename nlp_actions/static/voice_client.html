<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Command Client</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }
        
        .container {
            background: white;
            border-radius: 20px;
            padding: 30px;
            max-width: 500px;
            width: 100%;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        }
        
        h1 {
            color: #333;
            margin-bottom: 10px;
            text-align: center;
        }
        
        .subtitle {
            color: #666;
            text-align: center;
            margin-bottom: 30px;
            font-size: 14px;
        }
        
        .server-config {
            margin-bottom: 20px;
            padding: 15px;
            background: #f5f5f5;
            border-radius: 10px;
        }
        
        .server-config label {
            display: block;
            margin-bottom: 5px;
            color: #555;
            font-size: 14px;
            font-weight: 500;
        }
        
        .server-config input {
            width: 100%;
            padding: 10px;
            border: 2px solid #ddd;
            border-radius: 8px;
            font-size: 14px;
        }
        
        .server-config input:focus {
            outline: none;
            border-color: #667eea;
        }
        
        .button-container {
            display: flex;
            justify-content: center;
            margin-bottom: 30px;
        }
        
        #recordButton {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-size: 18px;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
            display: flex;
            align-items: center;
            justify-content: center;
            flex-direction: column;
        }
        
        #recordButton:hover {
            transform: scale(1.05);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
        }
        
        #recordButton:active {
            transform: scale(0.95);
        }
        
        #recordButton.recording {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            animation: pulse 1.5s ease-in-out infinite;
        }
        
        @keyframes pulse {
            0%, 100% {
                box-shadow: 0 4px 15px rgba(245, 87, 108, 0.4);
            }
            50% {
                box-shadow: 0 4px 25px rgba(245, 87, 108, 0.8);
            }
        }
        
        .status {
            text-align: center;
            margin-bottom: 20px;
            padding: 10px;
            border-radius: 8px;
            font-size: 14px;
            min-height: 20px;
        }
        
        .status.idle {
            color: #666;
        }
        
        .status.listening {
            color: #f5576c;
            font-weight: bold;
        }
        
        .status.processing {
            color: #667eea;
            font-weight: bold;
        }
        
        .result-box {
            margin-top: 20px;
            padding: 15px;
            background: #f9f9f9;
            border-radius: 10px;
            border-left: 4px solid #667eea;
        }
        
        .result-box h3 {
            color: #333;
            margin-bottom: 10px;
            font-size: 16px;
        }
        
        .result-item {
            margin-bottom: 10px;
        }
        
        .result-item:last-child {
            margin-bottom: 0;
        }
        
        .result-label {
            font-weight: 600;
            color: #555;
            font-size: 13px;
            margin-bottom: 3px;
        }
        
        .result-value {
            color: #333;
            font-size: 14px;
            word-wrap: break-word;
        }
        
        .error {
            background: #fee;
            border-left-color: #f5576c;
            color: #c33;
        }
        
        .success {
            background: #efe;
            border-left-color: #4caf50;
            color: #2e7d32;
        }
        
        .mic-icon {
            font-size: 48px;
            margin-bottom: 5px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Voice Commands</h1>
        <p class="subtitle">Speak your command to control the system</p>
        
        <div class="server-config">
                <label for="serverUrl">Server URL (optional):</label>
                <input type="text" id="serverUrl" value="" placeholder="Leave empty to use same origin">
        </div>
        
        <div class="button-container">
            <button id="recordButton">
                <div class="mic-icon">üé§</div>
                <div>Tap to Speak</div>
            </button>
        </div>
        
        <div style="text-align: center; margin-bottom: 15px;">
            <button id="testButton" style="padding: 8px 16px; background: #4caf50; color: white; border: none; border-radius: 6px; cursor: pointer; font-size: 14px;">
                Test Server Connection
            </button>
            <button id="tts-test" style="margin-left:8px; padding: 8px 12px; background:#2196f3; color:white; border:none; border-radius:6px; cursor:pointer; font-size:14px;">Test Voice</button>
        </div>
        
        <div id="status" class="status idle">Ready to listen</div>
        <div id="tts-status" class="status idle" style="font-size:12px; margin-top:8px;">TTS idle</div>
        
        <div style="margin-top: 20px; padding: 15px; background: #f5f5f5; border-radius: 10px;">
            <label style="display: block; margin-bottom: 8px; color: #555; font-size: 14px; font-weight: 500;">
                Or type your command:
            </label>
            <input type="text" id="textInput" placeholder="e.g., call my son" 
                   style="width: 100%; padding: 10px; border: 2px solid #ddd; border-radius: 8px; font-size: 14px;"
                   onkeypress="if(event.key === 'Enter') { sendTextInput(); }">
            <button onclick="sendTextInput()" 
                    style="margin-top: 10px; padding: 8px 16px; background: #667eea; color: white; border: none; border-radius: 6px; cursor: pointer; font-size: 14px; width: 100%;">
                Send Command
            </button>
        </div>
        
        <div id="result" style="display: none;"></div>
    </div>

    <script>
        // Suppress Chrome extension errors (they're harmless but annoying)
        window.addEventListener('error', (e) => {
            if (e.message && e.message.includes('message channel closed')) {
                e.preventDefault();
                console.warn('[Suppressed] Chrome extension message channel error (harmless)');
                return false;
            }
        });
        
        // Also catch unhandled promise rejections
        window.addEventListener('unhandledrejection', (e) => {
            if (e.reason && e.reason.message && e.reason.message.includes('message channel closed')) {
                e.preventDefault();
                console.warn('[Suppressed] Chrome extension promise rejection (harmless)');
                return false;
            }
        });
        
        const recordButton = document.getElementById('recordButton');
        const testButton = document.getElementById('testButton');
        const textInput = document.getElementById('textInput');
        const statusDiv = document.getElementById('status');
        const resultDiv = document.getElementById('result');
        const serverUrlInput = document.getElementById('serverUrl');
        
        let recognition = null;
        let isRecording = false;
        
        // Debug logging (can be enabled by uncommenting inside)
        function log(message, ...args) {
            // console.log('[Voice Client]', message, ...args);
        }

        // Helper to update connection status UI
        function updateConnectionStatus(text, cls = 'idle') {
            statusDiv.textContent = text;
            statusDiv.className = `status ${cls}`;
        }

        // TTS state for priming and voice readiness
        let ttsPrimed = false;
        let voicesReady = false;
        let ttsRetryCount = 0;

        // Initialize TTS listeners on load
        function initTTSListeners() {
            if (!('speechSynthesis' in window)) {
                console.warn('[TTS] speechSynthesis not supported');
                const status = document.getElementById('tts-status');
                if (status) status.textContent = 'TTS not supported on this device.';
                return;
            }

            // If voices already available, mark ready
            const v = window.speechSynthesis.getVoices();
            if (v && v.length > 0) {
                voicesReady = true;
                log('[TTS] voices ready (initial)');
            }

            // onvoiceschanged will fire on many mobile browsers when voices populate
            window.speechSynthesis.onvoiceschanged = () => {
                voicesReady = true;
                log('[TTS] voices ready (onvoiceschanged)');
                const status = document.getElementById('tts-status');
                if (status) status.textContent = 'TTS voices ready.';
            };
        }

        // Prime TTS with a short utterance so mobile allows subsequent playback
        function primeTTS() {
            if (ttsPrimed) return;
            if (!('speechSynthesis' in window)) return;
            ttsPrimed = true;
            try {
                // small silent utterance is sometimes preferable, but speaking a short phrase is more reliable
                const u = new SpeechSynthesisUtterance('Voice ready');
                u.lang = 'en-US';
                u.rate = 1.0;
                u.pitch = 1.0;
                u.onend = () => log('[TTS] priming utterance ended');
                window.speechSynthesis.speak(u);
                const status = document.getElementById('tts-status');
                if (status) status.textContent = 'TTS primed';
                log('[TTS] priming utterance spoken');
            } catch (e) {
                console.warn('[TTS] prime failed', e);
            }
        }

        // Robust speakText with retries if voices are not yet ready on mobile
        function speakText(text) {
            const status = document.getElementById('tts-status');
            if (status) status.textContent = `TTS called: "${text}"`;
            log('[TTS] speakText invoked with:', text);

            if (!text) return;
            if (!('speechSynthesis' in window)) {
                console.warn('[TTS] speechSynthesis not supported');
                if (status) status.textContent = 'TTS not supported on this device.';
                return;
            }

            // Ensure primed
            if (!ttsPrimed) {
                log('[TTS] not primed, priming now');
                primeTTS();
            }

            // If voices aren't ready yet, retry a few times with short delays
            if (!voicesReady) {
                if (ttsRetryCount < 6) {
                    ttsRetryCount += 1;
                    log(`[TTS] voices not ready, retry ${ttsRetryCount}/6`);
                    if (status) status.textContent = 'Waiting for TTS voices...';
                    setTimeout(() => speakText(text), 300);
                    return;
                } else {
                    log('[TTS] voices never became ready, proceeding anyway');
                }
            }

            try {
                window.speechSynthesis.cancel();

                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = 'en-US';
                utterance.rate = 1.0;  // not too fast
                utterance.pitch = 1.0;
                utterance.volume = 1.0;

                utterance.onstart = () => {
                    log('[TTS] onstart');
                    if (status) status.textContent = 'Speaking...';
                };
                utterance.onend = () => {
                    log('[TTS] onend');
                    if (status) status.textContent = 'TTS idle';
                };
                utterance.onerror = (e) => {
                    console.warn('[TTS] onerror', e);
                    if (status) status.textContent = 'TTS error';
                };

                window.speechSynthesis.speak(utterance);
            } catch (e) {
                console.warn('speakText failed', e);
                if (status) status.textContent = 'TTS failed';
            }
        }

    // Schedule a local TTS reminder to speak after `offsetSeconds` seconds.
    // This runs in the client's browser and does not depend on server push.
    function scheduleLocalReminder(offsetSeconds, message) {
        try {
            const status = document.getElementById('tts-status');
            if (status) status.textContent = `Scheduled reminder in ${offsetSeconds} seconds: ${message}`;

            // Show a small entry in the results area so user can see it's scheduled
            if (resultDiv) {
                const entry = document.createElement('div');
                entry.className = 'result-item';
                entry.innerHTML = `<div class="result-label">Scheduled reminder:</div><div class="result-value">In ${offsetSeconds}s ‚Äî ${message}</div>`;
                resultDiv.style.display = 'block';
                resultDiv.className = 'result-box';
                resultDiv.appendChild(entry);
            }

            setTimeout(() => {
                try {
                    speakText(message);
                    if (status) status.textContent = 'TTS idle';

                    // Append fired note to results
                    if (resultDiv) {
                        const fired = document.createElement('div');
                        fired.className = 'result-item';
                        fired.innerHTML = `<div class="result-label">Reminder fired:</div><div class="result-value">${message}</div>`;
                        resultDiv.appendChild(fired);
                    }
                } catch (e) {
                    console.warn('Local reminder speak failed', e);
                }
            }, Math.max(0, Number(offsetSeconds)) * 1000);
        } catch (e) {
            console.warn('scheduleLocalReminder failed', e);
        }
    }
        
        // Check for speech recognition support
        if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
            log('Speech recognition is supported');
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = false; // Changed back to false - stops after speech ends
            recognition.interimResults = true; // Show interim results for feedback
            recognition.lang = 'en-US';
            recognition.maxAlternatives = 1;
            
            // Increase timeout for no-speech detection
            // Note: This is a workaround - some browsers don't support this directly
            
            recognition.onstart = () => {
                log('Recognition started');
                isRecording = true;
                recordButton.classList.add('recording');
                recordButton.innerHTML = '<div class="mic-icon">üî¥</div><div>Click to Stop</div>';
                statusDiv.textContent = 'Listening... Speak your command now!';
                statusDiv.className = 'status listening';
            };
            
            recognition.onaudiostart = () => {
                log('Audio capture started');
            };
            
            recognition.onsoundstart = () => {
                log('Sound detected');
            };
            
            recognition.onspeechstart = () => {
                log('Speech detected - user is speaking');
                statusDiv.textContent = 'Speech detected! Keep speaking...';
            };
            
            recognition.onsoundend = () => {
                log('Sound ended');
            };
            
            recognition.onspeechend = () => {
                log('Speech ended - waiting for final result');
                statusDiv.textContent = 'Processing speech...';
            };
            
            recognition.onaudioend = () => {
                log('Audio capture ended');
            };
            
            recognition.onresult = (event) => {
                log('Recognition result received');
                let finalTranscript = '';
                let interimTranscript = '';
                
                // Separate final and interim results
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript + ' ';
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                // Show interim results as user speaks
                if (interimTranscript) {
                    statusDiv.textContent = `Heard: "${interimTranscript}"`;
                    log(`Interim transcript: "${interimTranscript}"`);
                }
                
                // Process final results
                if (finalTranscript.trim()) {
                    log(`Final transcript: "${finalTranscript.trim()}"`);
                    updateConnectionStatus('Processing...', 'processing');
                    
                    // Stop recognition and send to server
                    isRecording = false;
                    recognition.stop();
                    sendToServer(finalTranscript.trim());
                }
            };
            
            recognition.onerror = (event) => {
                log(`Recognition error: ${event.error}`);
                console.error('Speech recognition error:', event);
                
                let errorMsg = 'Error: ';
                switch(event.error) {
                    case 'no-speech':
                        // For no-speech, restart recognition automatically
                        log('No speech detected, restarting recognition...');
                        updateConnectionStatus('No speech detected. Try again - speak clearly!', 'error');
                        
                        // Auto-restart after a short delay
                        setTimeout(() => {
                            if (!isRecording) {
                                try {
                                    recognition.start();
                                    updateConnectionStatus('Listening again... Speak now!', 'listening');
                                } catch (e) {
                                    log(`Auto-restart failed: ${e.message}`);
                                    resetButton();
                                }
                            }
                        }, 500);
                        return; // Don't reset yet
                    case 'audio-capture':
                        errorMsg = 'Microphone not found or permission denied.';
                        break;
                    case 'not-allowed':
                        errorMsg = 'Microphone permission denied. Please allow microphone access.';
                        break;
                    case 'network':
                        errorMsg = 'Network error. Check your connection.';
                        break;
                    case 'aborted':
                        // Aborted is usually intentional, don't show error
                        log('Recognition aborted (likely intentional)');
                        return;
                    default:
                        errorMsg = `Error: ${event.error}`;
                }
                
                        updateConnectionStatus(errorMsg, 'error');
                resetButton();
            };
            
            recognition.onend = () => {
                log('Recognition ended - state:', recognition.state);
                
                // If we're still supposed to be recording and it ended due to no-speech,
                // we'll let the error handler restart it
                if (!isRecording) {
                    // User manually stopped, just reset
                    resetButton();
                    return;
                }
                
                // If it ended unexpectedly while we're still recording, 
                // it might be due to no-speech - the error handler will restart it
                // Otherwise, reset normally
                setTimeout(() => {
                    if (!isRecording) {
                        resetButton();
                    }
                }, 200);
            };
            
            recordButton.addEventListener('click', async () => {
                if (!isRecording) {
                    log('Button clicked - starting recognition');
                    
                    // Request microphone permission first
                    try {
                        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                        stream.getTracks().forEach(track => track.stop()); // Stop immediately, we just needed permission
                        log('Microphone permission granted');
                    } catch (err) {
                        log(`Microphone permission error: ${err.message}`);
                        updateConnectionStatus('Microphone permission denied. Please allow access and refresh.', 'error');
                        return;
                    }
                    
                    // Small delay to ensure everything is ready
                    await new Promise(resolve => setTimeout(resolve, 100));
                    
                    try {
                        // Check if recognition is already running
                        if (recognition && recognition.state && recognition.state !== 'idle') {
                            log('Recognition already running, stopping first');
                            recognition.stop();
                            await new Promise(resolve => setTimeout(resolve, 200));
                        }
                        
                        recognition.start();
                        log('Recognition.start() called');
                    } catch (e) {
                        log(`Error starting recognition: ${e.message}`);
                        console.error('Error starting recognition:', e);
                        
                        // Handle specific error cases
                        if (e.message && (e.message.includes('already started') || e.message.includes('started'))) {
                            statusDiv.textContent = 'Already listening. Please wait...';
                            // Try to stop and restart
                            try {
                                recognition.stop();
                                setTimeout(() => {
                                    try {
                                        recognition.start();
                                    } catch (e2) {
                                        log(`Retry failed: ${e2.message}`);
                                    }
                                }, 500);
                            } catch (e3) {
                                log(`Stop failed: ${e3.message}`);
                            }
                        } else {
                            statusDiv.textContent = `Error: ${e.message || 'Unknown error'}`;
                            statusDiv.className = 'status error';
                        }
                    }
                } else {
                    log('Button clicked - stopping recognition');
                    isRecording = false;
                    try {
                        // Give it a moment to finalize any pending results
                        setTimeout(() => {
                            recognition.stop();
                        }, 100);
                    } catch (e) {
                        log(`Error stopping recognition: ${e.message}`);
                    }
                }
            });
        } else {
            log('Speech recognition NOT supported');
            recordButton.disabled = true;
            recordButton.innerHTML = '<div>Not Supported</div>';
            statusDiv.textContent = 'Speech recognition not supported in this browser. Try Chrome or Edge.';
            statusDiv.className = 'status error';
        }
        
        function resetButton() {
            log('Resetting button');
            isRecording = false;
            recordButton.classList.remove('recording');
            recordButton.innerHTML = '<div class="mic-icon">üé§</div><div>Tap to Speak</div>';
            if (statusDiv.className === 'status processing') {
                // Keep processing status until response
                log('Keeping processing status');
            } else {
                        updateConnectionStatus('Ready to listen', 'idle');
            }
        }

        // Helper: format HH:MM (24h) to spoken 12-hour time like "2:30 PM"
        function formatTimeForSpeech(timeStr) {
            if (!timeStr) return '';
            // Accept formats like "14:30" or "9:00" or "09:00"
            const m = timeStr.match(/^(\d{1,2}):(\d{2})$/);
            if (!m) return timeStr;
            let h = parseInt(m[1], 10);
            const minute = m[2];
            const ampm = h >= 12 ? 'PM' : 'AM';
            let displayHour = h % 12;
            if (displayHour === 0) displayHour = 12;
            return `${displayHour}:${minute} ${ampm}`;
        }
        
        async function sendToServer(text) {
            const userUrl = serverUrlInput.value.trim();
            const base = userUrl || window.location.origin;
            const endpoint = `${base.replace(/\/$/, '')}/voice`;

            log(`Sending to server: ${endpoint}`);
            log(`Text: "${text}"`);

            try {
                const response = await fetch(endpoint, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ text: text })
                });
                
                log(`Response status: ${response.status}`);
                
                if (!response.ok) {
                    throw new Error(`Server error: ${response.status} ${response.statusText}`);
                }
                
                const data = await response.json();
                log('Response data:', data);

                updateConnectionStatus('Command processed', 'idle');

                displayResult(text, data);

                // Build a spoken response based on server response
                try {
                    const res = data.result || {};
                    const intent = data.intent || {};
                    let spoken = null;

                    const action = res.action || intent.action || '';

                    if (action === 'CALL_CONTACT') {
                        const contact = res.contact_key || (intent.slots && intent.slots.contact) || 'contact';
                        spoken = `Calling your ${contact} now.`;
                    } else if (action === 'SET_MEDICATION_REMINDER') {
                        const timeStr = res.time || (intent.slots && intent.slots.time) || null;
                        const label = res.label || (intent.slots && intent.slots.label) || 'medication';
                        const fmt = formatTimeForSpeech(timeStr);
                        spoken = timeStr ? `Okay, I'll remind you at ${fmt} to take your ${label}.` : `Okay, reminder saved for ${label}.`;
                    } else if (action === 'START_MONITORING') {
                        spoken = 'Monitoring started. I will keep watching over you.';
                    } else if (action === 'STOP_MONITORING') {
                        spoken = 'Monitoring stopped. I will stay nearby but not actively monitoring.';
                    } else if (res.ok === false && res.error) {
                        spoken = res.error;
                    } else if (data.message) {
                        spoken = data.message;
                    } else {
                        // Generic fallback: read details if available, otherwise polite unknown
                        spoken = 'Okay.';
                    }

                    if (spoken) speakText(spoken);
                } catch (e) {
                    log('Error building spoken response:', e);
                }
                // If server created a relative reminder, schedule local TTS
                try {
                    // Support multiple response shapes: top-level slots or intent.slots
                    const slots = data.slots || (data.intent && data.intent.slots) || (data.result && data.result.slots) || {};
                    const offset = slots && slots.offset_seconds ? Number(slots.offset_seconds) : null;
                    const task = slots && (slots.task || slots.label || slots.text) ? (slots.task || slots.label || slots.text) : null;
                    if (offset && !isNaN(offset) && offset > 0) {
                        const speakMsg = task ? `Reminder: ${task}` : (data.message || 'Reminder');
                        scheduleLocalReminder(offset, speakMsg);
                    }
                } catch (e) {
                    log('Error scheduling local reminder TTS:', e);
                }
            } catch (error) {
                log(`Error sending to server: ${error.message}`);
                console.error('Error sending to server:', error);
                updateConnectionStatus(`Error: ${error.message}`, 'error');
                displayError(error.message);
            } finally {
                resetButton();
            }
        }
        
        function displayResult(originalText, response) {
            resultDiv.style.display = 'block';
            
            const intent = response.intent || {};
            const result = response.result || {};
            
            const isSuccess = result.ok !== false;
            resultDiv.className = `result-box ${isSuccess ? 'success' : 'error'}`;
            
            resultDiv.innerHTML = `
                <h3>${isSuccess ? '‚úÖ Command Processed' : '‚ùå Error'}</h3>
                <div class="result-item">
                    <div class="result-label">You said:</div>
                    <div class="result-value">"${originalText}"</div>
                </div>
                <div class="result-item">
                    <div class="result-label">Action:</div>
                    <div class="result-value">${intent.action || 'Unknown'}</div>
                </div>
                ${intent.slots && Object.keys(intent.slots).length > 0 ? `
                    <div class="result-item">
                        <div class="result-label">Details:</div>
                        <div class="result-value">${JSON.stringify(intent.slots, null, 2)}</div>
                    </div>
                ` : ''}
                ${result.error ? `
                    <div class="result-item">
                        <div class="result-label">Error:</div>
                        <div class="result-value">${result.error}</div>
                    </div>
                ` : ''}
            `;
            // If backend provided a human-readable message, speak it; otherwise handled elsewhere
            if (response && response.message) {
                speakText(response.message);
            } else {
                // Some actions speak in sendToServer; for safety, if result contains error, speak it
                const res = response.result || {};
                if (res && res.ok === false && res.error) {
                    speakText(res.error);
                }
            }
        }
        
        function displayError(errorMessage) {
            resultDiv.style.display = 'block';
            resultDiv.className = 'result-box error';
            resultDiv.innerHTML = `
                <h3>‚ùå Connection Error</h3>
                <div class="result-value">${errorMessage}</div>
                <div class="result-value" style="margin-top: 10px; font-size: 12px; color: #666;">
                    Make sure the server is running and the URL is correct.
                </div>
            `;
            // Speak error for accessibility
            speakText('There was a connection problem. Please try again.');
        }
        
        // Test server connection
        testButton.addEventListener('click', async () => {
            const userUrl = serverUrlInput.value.trim();
            const base = userUrl || window.location.origin;
            updateConnectionStatus('Testing connection...', 'processing');

            try {
                const response = await fetch(`${base.replace(/\/$/, '')}/status`);
                if (response.ok) {
                    const data = await response.json();
                    updateConnectionStatus('‚úÖ Server connected!', 'success');
                    log('Server test successful:', data);

                    // Build and speak a status summary
                    try {
                        const monitoring = data.monitoring_state;
                        const reminders = data.reminders || [];
                        let spoken = monitoring ? 'Monitoring is ON. ' : 'Monitoring is OFF. ';

                        if (reminders.length === 0) {
                            spoken += 'You have no reminders.';
                        } else {
                            spoken += `You have ${reminders.length} reminder${reminders.length > 1 ? 's' : ''}: `;
                            const parts = reminders.map(r => {
                                const t = r.time || r.time_str || '';
                                const label = r.label || r.text || '';
                                return t ? `${formatTimeForSpeech(t)} ${label}`.trim() : label;
                            });
                            spoken += parts.join(', ');
                        }

                        speakText(spoken);
                    } catch (e) {
                        log('Error building spoken status:', e);
                    }
                } else {
                    throw new Error(`Server returned ${response.status}`);
                }
            } catch (error) {
                updateConnectionStatus(`‚ùå Connection failed: ${error.message}`, 'error');
                log('Server test failed:', error);
                // Speak the connection problem
                speakText('There was a connection problem. Please try again.');
            }
        });
        
        // Function to send text input
        function sendTextInput() {
            const text = textInput.value.trim();
            if (!text) {
                statusDiv.textContent = 'Please enter a command';
                statusDiv.className = 'status error';
                return;
            }
            
            log('Sending text input:', text);
            statusDiv.textContent = 'Processing...';
            statusDiv.className = 'status processing';
            sendToServer(text);
            textInput.value = '';
        }
        
        // Make sendTextInput available globally
        window.sendTextInput = sendTextInput;
        
        // Default server URL: use same origin if user leaves input empty.
        // Do NOT force http://host:5000 patterns which break HTTPS/Cloudflare.
        if (!serverUrlInput.value.trim()) {
            serverUrlInput.placeholder = window.location.origin + ' (default)';
        }
        
        // Test microphone access on page load
        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {
                log('Microphone access confirmed');
                stream.getTracks().forEach(track => track.stop());
                updateConnectionStatus('Ready to listen (microphone OK)', 'idle');
            })
            .catch(err => {
                log('Microphone access error:', err.message);
                updateConnectionStatus('‚ö†Ô∏è Microphone access denied. Please allow access and refresh.', 'error');
            });

        // Helper to create a secure WebSocket for current origin + path.
        // Usage: const ws = createOriginWebSocket('/audio');
        function createOriginWebSocket(path) {
            const wsProtocol = window.location.protocol === 'https:' ? 'wss' : 'ws';
            const wsHost = window.location.host;
            const normalizedPath = path.startsWith('/') ? path : '/' + path;
            const url = `${wsProtocol}://${wsHost}${normalizedPath}`;
            log('Opening WebSocket:', url);
            return new WebSocket(url);
        }

        // DOMContentLoaded: initialize TTS listeners and prime on first user gesture
        document.addEventListener('DOMContentLoaded', () => {
            initTTSListeners();

            // Prime on first tap/click anywhere (mobile requires user gesture)
            document.addEventListener('click', () => {
                primeTTS();
            }, { once: true });

            // Wire the TTS test button
            const ttsTestBtn = document.getElementById('tts-test');
            if (ttsTestBtn) {
                ttsTestBtn.addEventListener('click', (e) => {
                    // This is a user gesture so priming/speech will be allowed
                    primeTTS();
                    speakText('This is a test of the voice on your phone.');
                });
            }
        });
    </script>
</body>
</html>

